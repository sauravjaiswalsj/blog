---
slug: mdx-blog-post
title: ML ALGORITHMS
authors: [saurav]
tags: [ML]
---

# COMPLETE MACHINE LEARNING ALGORITHMS LIST

---

## 1. Supervised Learning Algorithms

### 1.1 Regression

* Linear Regression
* Multiple Linear Regression
* Polynomial Regression
* Ridge Regression
* Lasso Regression
* Elastic Net
* Bayesian Linear Regression
* Quantile Regression
* Poisson Regression
* Support Vector Regression (SVR)
* K-Nearest Neighbors Regression
* Decision Tree Regression
* Random Forest Regression
* Extra Trees Regression
* Gradient Boosting Regression
* AdaBoost Regression
* XGBoost Regression
* LightGBM Regression
* CatBoost Regression

---

### 1.2 Classification

* Logistic Regression
* Naive Bayes

  * Gaussian
  * Multinomial
  * Bernoulli
* K-Nearest Neighbors (KNN)
* Support Vector Machine (SVM)
* Decision Tree Classifier
* Random Forest Classifier
* Extra Trees Classifier
* AdaBoost
* Gradient Boosting
* XGBoost
* LightGBM
* CatBoost
* Linear Discriminant Analysis (LDA)
* Quadratic Discriminant Analysis (QDA)
* Perceptron
* Passive-Aggressive Algorithms
* Nearest Centroid

---

## 2. Unsupervised Learning Algorithms

### 2.1 Clustering

* K-Means
* K-Means++
* K-Medoids (PAM)
* Hierarchical Clustering

  * Agglomerative
  * Divisive
* DBSCAN
* HDBSCAN
* OPTICS
* Mean Shift
* Spectral Clustering
* Affinity Propagation
* BIRCH
* Gaussian Mixture Models (GMM)

---

### 2.2 Dimensionality Reduction

* Principal Component Analysis (PCA)
* Kernel PCA
* Independent Component Analysis (ICA)
* Linear Discriminant Analysis (LDA)
* t-SNE
* UMAP
* Truncated SVD
* Factor Analysis
* Autoencoders

---

### 2.3 Association Rule Learning

* Apriori
* FP-Growth
* Eclat

---

## 3. Semi-Supervised Learning Algorithms

* Self-Training
* Co-Training
* Pseudo-Labeling
* Label Propagation
* Label Spreading
* Semi-Supervised SVM

---

## 4. Reinforcement Learning Algorithms

### 4.1 Classical RL

* Markov Decision Process (MDP)
* Dynamic Programming
* Monte Carlo Methods
* Temporal Difference (TD) Learning
* Q-Learning
* SARSA

---

### 4.2 Deep Reinforcement Learning

* Deep Q-Network (DQN)
* Double DQN
* Dueling DQN
* Policy Gradient
* REINFORCE
* Actor-Critic
* A2C
* A3C
* PPO (Proximal Policy Optimization)
* TRPO
* DDPG
* TD3
* SAC (Soft Actor-Critic)

---

## 5. Deep Learning Algorithms

### 5.1 Neural Networks

* Artificial Neural Network (ANN)
* Feedforward Neural Network
* Multilayer Perceptron (MLP)

---

### 5.2 Convolutional Neural Networks

* CNN
* LeNet
* AlexNet
* VGG
* GoogLeNet / Inception
* ResNet
* DenseNet
* MobileNet
* EfficientNet

---

### 5.3 Recurrent Neural Networks

* RNN
* LSTM
* GRU
* Bidirectional RNN

---

### 5.4 Transformers

* Transformer
* BERT
* GPT
* T5
* Vision Transformer (ViT)

---

### 5.5 Generative Models

* Autoencoder
* Variational Autoencoder (VAE)
* GAN

  * DCGAN
  * CycleGAN
  * StyleGAN
* Diffusion Models

---

## 6. Ensemble Learning Algorithms

* Bagging
* Boosting
* Stacking
* Voting Classifier
* Random Forest
* Gradient Boosting Machines

---

## 7. Anomaly / Outlier Detection

* Isolation Forest
* One-Class SVM
* Local Outlier Factor (LOF)
* Elliptic Envelope
* Autoencoder-based Anomaly Detection

---

## 8. Time Series Algorithms

* ARIMA
* SARIMA
* SARIMAX
* Holt-Winters
* Prophet
* LSTM for Time Series
* Temporal Convolutional Networks (TCN)

---

## 9. Online / Incremental Learning

* Stochastic Gradient Descent Classifier
* SGD Regressor
* Hoeffding Tree
* Online Passive-Aggressive Algorithms

---

## 10. Optimization Algorithms (INCLUDING GRADIENT DESCENT)

### Gradient-Based Optimization

* Gradient Descent (Batch)
* Stochastic Gradient Descent (SGD)
* Mini-Batch Gradient Descent

### Gradient Descent Variants

* Momentum
* Nesterov Accelerated Gradient (NAG)
* AdaGrad
* RMSProp
* Adam
* AdamW
* Adadelta
* Nadam
* AMSGrad

### Other Optimizers

* Newton’s Method
* L-BFGS
* Coordinate Descent

---

## 11. Evolutionary & Probabilistic Algorithms

* Genetic Algorithm
* Genetic Programming
* Evolution Strategies
* Differential Evolution
* Particle Swarm Optimization
* Ant Colony Optimization
* Bayesian Optimization

---

## Key Clarification (Important)

* **ML Models** → Make predictions
* **Optimization Algorithms (Gradient Descent)** → Train models
* **Loss Functions** → Define what “error” means

Gradient Descent is **core to ML**, but it is **not a predictive model itself**.

